{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Level LSTM Config 2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMemBHD5Is_0",
        "colab_type": "text"
      },
      "source": [
        "Word Level LSTM for trigrams (sequence length: 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-1WNNP7lkPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "65983a86-2b6d-431b-89de-b2c8f6f6d595"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTn14jP4lpk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "893f3a16-de7f-47dc-8aff-2ccf0fc1d5e0"
      },
      "source": [
        "cd ../gdrive/My\\ Drive/NLP/Project/Final\\ Project/LSTM/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/My Drive/NLP/Project/Final Project/LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWOIekeu-n2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "4ed463a3-1c32-4a5b-9fe8-7ecbf03f2018"
      },
      "source": [
        "ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'10 letters window 10 epochs of LSTM Next word Prediction.ipynb'\n",
            "'10 letters window 50 epochs of LSTM Next word Prediction.ipynb'\n",
            " \u001b[0m\u001b[01;34mcheckpoints\u001b[0m/\n",
            " data.txt\n",
            " examples.txt\n",
            "'LSTM Next word Prediction.ipynb'\n",
            " lstm_train.py\n",
            " model.h5\n",
            " pima_indians.txt\n",
            " republic.txt\n",
            " requirements.txt\n",
            " tokenizer.pkl\n",
            " vocabulary.txt\n",
            "'Word Level LSTM.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZjH0GA0m60Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuPdxkZ6X1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'republic.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxKACktEhNQL",
        "colab_type": "code",
        "outputId": "959f915a-4318-4fef-8eb2-519f948bd930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "sequences[1:10]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [30, 1614, 5, 26, 1, 163, 2, 2549, 2550, 35, 44, 2871, 3, 28],\n",
              " [568, 44, 3940, 4907, 21, 37, 1062, 73, 235, 73, 248, 13],\n",
              " [2551, 163, 73, 157, 1, 379, 2, 1, 286, 264, 1178, 1325],\n",
              " [28, 30, 1614, 13, 3323, 35, 2552, 264, 1404],\n",
              " [],\n",
              " [],\n",
              " [2069, 1, 227],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7Df-vKhpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in sequences for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAOOpT55jARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 2\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(flat_list) - seq_length, 1):\n",
        "\tseq_in = flat_list[i:i + seq_length]\n",
        "\tseq_out = flat_list[i + seq_length]\n",
        "\tdataX.append(seq_in)\n",
        "\tdataY.append(seq_out)\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTpNMayajlYe",
        "colab_type": "code",
        "outputId": "216fe05a-4fdd-4e07-d57c-38706732d09c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patterns"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221275"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Ba1MRjlNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = array(dataX)\n",
        "dataY = array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqbJSLSj9aw",
        "colab_type": "code",
        "outputId": "24b01fa8-e98e-4e9a-f03a-e0aaa9c4fc55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataX.shape, dataY.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((221275, 2), (221275,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQJLFWPbqbl",
        "colab_type": "code",
        "outputId": "ff6e118b-6c3c-4a91-e393-7cc442b6d985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separate into input and output\n",
        "X, y = dataX, dataY\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = dataX.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 2, 50)             551800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 2, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11036)             1114636   \n",
            "=================================================================\n",
            "Total params: 1,817,336\n",
            "Trainable params: 1,817,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Epoch 1/50\n",
            "221275/221275 [==============================] - 37s 165us/step - loss: 6.3236 - acc: 0.0821\n",
            "Epoch 2/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 5.7529 - acc: 0.1251\n",
            "Epoch 3/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 5.4442 - acc: 0.1549\n",
            "Epoch 4/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 5.2245 - acc: 0.1707\n",
            "Epoch 5/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 5.0620 - acc: 0.1814\n",
            "Epoch 6/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.9196 - acc: 0.1888\n",
            "Epoch 7/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.7914 - acc: 0.1960\n",
            "Epoch 8/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.6712 - acc: 0.2020\n",
            "Epoch 9/50\n",
            "221275/221275 [==============================] - 35s 157us/step - loss: 4.5589 - acc: 0.2077\n",
            "Epoch 10/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.4519 - acc: 0.2135\n",
            "Epoch 11/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 4.3503 - acc: 0.2185\n",
            "Epoch 12/50\n",
            "221275/221275 [==============================] - 33s 150us/step - loss: 4.2552 - acc: 0.2238\n",
            "Epoch 13/50\n",
            "221275/221275 [==============================] - 32s 147us/step - loss: 4.1647 - acc: 0.2293\n",
            "Epoch 14/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.0797 - acc: 0.2348\n",
            "Epoch 15/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 4.0014 - acc: 0.2413\n",
            "Epoch 16/50\n",
            "221275/221275 [==============================] - 32s 146us/step - loss: 3.9299 - acc: 0.2482\n",
            "Epoch 17/50\n",
            "221275/221275 [==============================] - 32s 146us/step - loss: 3.8658 - acc: 0.2549\n",
            "Epoch 18/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.8062 - acc: 0.2612\n",
            "Epoch 19/50\n",
            "221275/221275 [==============================] - 32s 147us/step - loss: 3.7524 - acc: 0.2676\n",
            "Epoch 20/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.7039 - acc: 0.2727\n",
            "Epoch 21/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.6595 - acc: 0.2780\n",
            "Epoch 22/50\n",
            "221275/221275 [==============================] - 32s 146us/step - loss: 3.6176 - acc: 0.2827\n",
            "Epoch 23/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.5792 - acc: 0.2872\n",
            "Epoch 24/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.5412 - acc: 0.2917\n",
            "Epoch 25/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.5078 - acc: 0.2949\n",
            "Epoch 26/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.4748 - acc: 0.2996\n",
            "Epoch 27/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.4436 - acc: 0.3036\n",
            "Epoch 28/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.4150 - acc: 0.3077\n",
            "Epoch 29/50\n",
            "221275/221275 [==============================] - 32s 147us/step - loss: 3.3865 - acc: 0.3103\n",
            "Epoch 30/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.3608 - acc: 0.3133\n",
            "Epoch 31/50\n",
            "221275/221275 [==============================] - 33s 151us/step - loss: 3.3345 - acc: 0.3165\n",
            "Epoch 32/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.3099 - acc: 0.3200\n",
            "Epoch 33/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.2869 - acc: 0.3233\n",
            "Epoch 34/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.2640 - acc: 0.3257\n",
            "Epoch 35/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.2438 - acc: 0.3279\n",
            "Epoch 36/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.2223 - acc: 0.3307\n",
            "Epoch 37/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.2021 - acc: 0.3339\n",
            "Epoch 38/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.1841 - acc: 0.3353\n",
            "Epoch 39/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.1645 - acc: 0.3377\n",
            "Epoch 40/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.1472 - acc: 0.3404\n",
            "Epoch 41/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.1293 - acc: 0.3427\n",
            "Epoch 42/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.1130 - acc: 0.3452\n",
            "Epoch 43/50\n",
            "221275/221275 [==============================] - 33s 150us/step - loss: 3.0950 - acc: 0.3466\n",
            "Epoch 44/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.0811 - acc: 0.3484\n",
            "Epoch 45/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.0657 - acc: 0.3499\n",
            "Epoch 46/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 3.0500 - acc: 0.3521\n",
            "Epoch 47/50\n",
            "221275/221275 [==============================] - 33s 147us/step - loss: 3.0356 - acc: 0.3534\n",
            "Epoch 48/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.0224 - acc: 0.3558\n",
            "Epoch 49/50\n",
            "221275/221275 [==============================] - 33s 148us/step - loss: 3.0092 - acc: 0.3577\n",
            "Epoch 50/50\n",
            "221275/221275 [==============================] - 33s 149us/step - loss: 2.9940 - acc: 0.3594\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtqEUoAxg2bq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "748737c3-4c32-4d7e-dba4-d81d96fa16fa"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbS6tW2P_Qts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLXGphOoAgCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFwiReEW_sv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select a seed text\n",
        "seed_text = \"shut the\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmSUAT-jAouc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81148fb4-c857-4243-892e-0fa60fe823e5"
      },
      "source": [
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, 2, seed_text, 1)\n",
        "print(generated)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gates\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKc5wWbQBX4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "2f652869-14cf-471e-8d69-26d410a1b3a4"
      },
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import collections\n",
        "\n",
        "blogs = open('republic.txt', 'rt')\n",
        "text = blogs.read()\n",
        "blogs.close()\n",
        "corpus = text\n",
        "# We will remove double quotes, !, ? $, #, etc\n",
        "# specify to translate chars \n",
        "str1 = \"\"\n",
        "# specify to replace with \n",
        "str2 = \"\"\n",
        "# delete chars \n",
        "str3 = \"\\\"!?#$%^&*+\"\n",
        "\n",
        "trg = corpus\n",
        "table = trg.maketrans(str1, str2, str3)\n",
        "corpus = trg.translate(table)\n",
        "words = corpus.split()\n",
        "\n",
        "freq_dist = nltk.FreqDist(words)\n",
        "freq_dist.most_common(10) # the most common words in our corpus.\n",
        "\n",
        "# esBigrams = ngrams(words, 2)\n",
        "# esBigramFreq = collections.Counter(esBigrams)\n",
        "# esBigramFreq.most_common(10)\n",
        "\n",
        "esTrigrams = ngrams(words, 3)\n",
        "esTrigramFreq = collections.Counter(esTrigrams)\n",
        "esTrigramFreq.most_common(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('as', 'well', 'as'), 113),\n",
              " (('to', 'be', 'the'), 109),\n",
              " (('is', 'to', 'be'), 76),\n",
              " (('which', 'is', 'the'), 74),\n",
              " (('Yes,', 'he', 'said,'), 74),\n",
              " (('are', 'to', 'be'), 70),\n",
              " (('the', 'nature', 'of'), 68),\n",
              " (('the', 'idea', 'of'), 67),\n",
              " (('there', 'is', 'no'), 66),\n",
              " (('he', 'said.', 'And'), 66)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}