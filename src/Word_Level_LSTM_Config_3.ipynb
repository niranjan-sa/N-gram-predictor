{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word_Level_LSTM_Config_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKDYuJbpI_xw",
        "colab_type": "text"
      },
      "source": [
        "Word Level LSTM for five-grams (sequence length: 4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-1WNNP7lkPU",
        "colab_type": "code",
        "outputId": "011f7346-1e5d-49e9-b588-25258463736c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jL-wqa1qtj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "158898f6-2693-412e-f7c7-cff641061a87"
      },
      "source": [
        "ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.txt  model.h5  republic.txt  tokenizer.pkl  Word_Level_LSTM_Config_3.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttetpn-tEBno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6ae662fc-8608-4067-c411-d171f5702fb8"
      },
      "source": [
        "cd ../gdrive/My\\ Drive/NLP/Project"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/My Drive/NLP/Project/Final Project/LSTM/'\n",
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuPdxkZ6X1GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "from pickle import dump\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "\t# open the file as read only\n",
        "\tfile = open(filename, 'r')\n",
        "\t# read all text\n",
        "\ttext = file.read()\n",
        "\t# close the file\n",
        "\tfile.close()\n",
        "\treturn text\n",
        "\n",
        "# load\n",
        "in_filename = 'republic.txt'\n",
        "doc = load_doc(in_filename)\n",
        "lines = doc.split('\\n')\n",
        "\n",
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(lines)\n",
        "sequences = tokenizer.texts_to_sequences(lines)\n",
        "# vocabulary size\n",
        "vocab_size = len(tokenizer.word_index) + 1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxKACktEhNQL",
        "colab_type": "code",
        "outputId": "c6945e83-8a58-490c-c6aa-fa26e17c5ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "sequences[1:10]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [30, 1614, 5, 26, 1, 163, 2, 2549, 2550, 35, 44, 2871, 3, 28],\n",
              " [568, 44, 3940, 4907, 21, 37, 1062, 73, 235, 73, 248, 13],\n",
              " [2551, 163, 73, 157, 1, 379, 2, 1, 286, 264, 1178, 1325],\n",
              " [28, 30, 1614, 13, 3323, 35, 2552, 264, 1404],\n",
              " [],\n",
              " [],\n",
              " [2069, 1, 227],\n",
              " []]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7Df-vKhpZ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = [item for sublist in sequences for item in sublist]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAOOpT55jARk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 4\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, len(flat_list) - seq_length, 1):\n",
        "\tseq_in = flat_list[i:i + seq_length]\n",
        "\tseq_out = flat_list[i + seq_length]\n",
        "\tdataX.append(seq_in)\n",
        "\tdataY.append(seq_out)\n",
        "n_patterns = len(dataX)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTpNMayajlYe",
        "colab_type": "code",
        "outputId": "09e3b8e7-b7f0-4eb2-b5a7-fe25369a1a80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_patterns"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "221273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rY_Ba1MRjlNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataX = array(dataX)\n",
        "dataY = array(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqbJSLSj9aw",
        "colab_type": "code",
        "outputId": "982b42bf-be2a-46b0-c1b3-906c591286c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataX.shape, dataY.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((221273, 4), (221273,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkQJLFWPbqbl",
        "colab_type": "code",
        "outputId": "8de43509-e24b-4a68-a03f-dc51cdde4d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# separate into input and output\n",
        "X, y = dataX, dataY\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = dataX.shape[1]\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "print(model.summary())\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, batch_size=128, epochs=50)\n",
        "\n",
        "# save the model to file\n",
        "model.save('model.h5')\n",
        "# save the tokenizer\n",
        "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4, 50)             551800    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 4, 100)            60400     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 11036)             1114636   \n",
            "=================================================================\n",
            "Total params: 1,817,336\n",
            "Trainable params: 1,817,336\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "221273/221273 [==============================] - 42s 191us/step - loss: 6.3862 - acc: 0.0774\n",
            "Epoch 2/50\n",
            "221273/221273 [==============================] - 38s 170us/step - loss: 5.8065 - acc: 0.1241\n",
            "Epoch 3/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 5.4356 - acc: 0.1563\n",
            "Epoch 4/50\n",
            "221273/221273 [==============================] - 37s 168us/step - loss: 5.2054 - acc: 0.1734\n",
            "Epoch 5/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 5.0240 - acc: 0.1854\n",
            "Epoch 6/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 4.8664 - acc: 0.1934\n",
            "Epoch 7/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 4.7189 - acc: 0.2013\n",
            "Epoch 8/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 4.5805 - acc: 0.2082\n",
            "Epoch 9/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 4.4481 - acc: 0.2134\n",
            "Epoch 10/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 4.3219 - acc: 0.2203\n",
            "Epoch 11/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 4.1994 - acc: 0.2264\n",
            "Epoch 12/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 4.0819 - acc: 0.2342\n",
            "Epoch 13/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 3.9711 - acc: 0.2411\n",
            "Epoch 14/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 3.8647 - acc: 0.2504\n",
            "Epoch 15/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 3.7643 - acc: 0.2615\n",
            "Epoch 16/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 3.6725 - acc: 0.2726\n",
            "Epoch 17/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 3.5875 - acc: 0.2831\n",
            "Epoch 18/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 3.5079 - acc: 0.2926\n",
            "Epoch 19/50\n",
            "221273/221273 [==============================] - 37s 167us/step - loss: 3.4336 - acc: 0.3020\n",
            "Epoch 20/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 3.3643 - acc: 0.3119\n",
            "Epoch 21/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 3.2982 - acc: 0.3205\n",
            "Epoch 22/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 3.2362 - acc: 0.3304\n",
            "Epoch 23/50\n",
            "221273/221273 [==============================] - 36s 162us/step - loss: 3.1765 - acc: 0.3393\n",
            "Epoch 24/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 3.1202 - acc: 0.3472\n",
            "Epoch 25/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 3.0665 - acc: 0.3566\n",
            "Epoch 26/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 3.0149 - acc: 0.3636\n",
            "Epoch 27/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 2.9644 - acc: 0.3721\n",
            "Epoch 28/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 2.9176 - acc: 0.3795\n",
            "Epoch 29/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 2.8732 - acc: 0.3879\n",
            "Epoch 30/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.8287 - acc: 0.3944\n",
            "Epoch 31/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 2.7865 - acc: 0.4012\n",
            "Epoch 32/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 2.7477 - acc: 0.4081\n",
            "Epoch 33/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.7081 - acc: 0.4155\n",
            "Epoch 34/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 2.6706 - acc: 0.4218\n",
            "Epoch 35/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.6361 - acc: 0.4270\n",
            "Epoch 36/50\n",
            "221273/221273 [==============================] - 37s 169us/step - loss: 2.6024 - acc: 0.4338\n",
            "Epoch 37/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.5693 - acc: 0.4397\n",
            "Epoch 38/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 2.5380 - acc: 0.4441\n",
            "Epoch 39/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 2.5063 - acc: 0.4504\n",
            "Epoch 40/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.4764 - acc: 0.4561\n",
            "Epoch 41/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.4475 - acc: 0.4607\n",
            "Epoch 42/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 2.4205 - acc: 0.4660\n",
            "Epoch 43/50\n",
            "221273/221273 [==============================] - 37s 166us/step - loss: 2.3947 - acc: 0.4694\n",
            "Epoch 44/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 2.3712 - acc: 0.4749\n",
            "Epoch 45/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.3444 - acc: 0.4788\n",
            "Epoch 46/50\n",
            "221273/221273 [==============================] - 36s 165us/step - loss: 2.3239 - acc: 0.4824\n",
            "Epoch 47/50\n",
            "221273/221273 [==============================] - 36s 163us/step - loss: 2.3007 - acc: 0.4863\n",
            "Epoch 48/50\n",
            "221273/221273 [==============================] - 36s 164us/step - loss: 2.2775 - acc: 0.4905\n",
            "Epoch 49/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 2.2550 - acc: 0.4943\n",
            "Epoch 50/50\n",
            "221273/221273 [==============================] - 37s 165us/step - loss: 2.2347 - acc: 0.4980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTa1Hhm7eprb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "029fd0a0-7e62-4810-e2bd-0421e5011848"
      },
      "source": [
        "from random import randint\n",
        "from pickle import load\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# load the model\n",
        "model = load_model('model.h5')\n",
        "# load the tokenizer\n",
        "tokenizer = load(open('tokenizer.pkl', 'rb'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtqEUoAxg2bq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate a sequence from a language model\n",
        "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
        "\tresult = list()\n",
        "\tin_text = seed_text\n",
        "\t# generate a fixed number of words\n",
        "\tfor _ in range(n_words):\n",
        "\t\t# encode the text as integer\n",
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n",
        "\t\t# truncate sequences to a fixed length\n",
        "\t\tencoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
        "\t\t# predict probabilities for each word\n",
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n",
        "\t\t# map predicted word index to word\n",
        "\t\tout_word = ''\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == yhat:\n",
        "\t\t\t\tout_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\t# append to input\n",
        "\t\tin_text += ' ' + out_word\n",
        "\t\tresult.append(out_word)\n",
        "\treturn ' '.join(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlbs99JkF9jJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b4d4ad0-6cef-449f-f80f-98b1b375ad46"
      },
      "source": [
        "# select a seed text\n",
        "seed_text = \"very true he\"\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, 4, seed_text, 1)\n",
        "print(generated)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P71ZU89gIHv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12136a98-d3d9-44ea-b6c3-84dbab1cf8ee"
      },
      "source": [
        "# select a seed text\n",
        "seed_text = \"very true\"\n",
        "# generate new text\n",
        "generated = generate_seq(model, tokenizer, 4, seed_text, 2)\n",
        "print(generated)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ukq8XhNbGEDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "22f94fec-410b-400b-df1e-8787c759d26f"
      },
      "source": [
        "# for our verification\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "import collections\n",
        "\n",
        "blogs = open('republic.txt', 'rt')\n",
        "text = blogs.read()\n",
        "blogs.close()\n",
        "corpus = text\n",
        "# We will remove double quotes, !, ? $, #, etc\n",
        "# specify to translate chars \n",
        "str1 = \"\"\n",
        "# specify to replace with \n",
        "str2 = \"\"\n",
        "# delete chars \n",
        "str3 = \"\\\"!?#$%^&*+\"\n",
        "\n",
        "trg = corpus\n",
        "table = trg.maketrans(str1, str2, str3)\n",
        "corpus = trg.translate(table)\n",
        "words = corpus.split()\n",
        "\n",
        "freq_dist = nltk.FreqDist(words)\n",
        "freq_dist.most_common(10) # the most common words in our corpus.\n",
        "\n",
        "# esBigrams = ngrams(words, 2)\n",
        "# esBigramFreq = collections.Counter(esBigrams)\n",
        "# esBigramFreq.most_common(10)\n",
        "\n",
        "# esTrigrams = ngrams(words, 3)\n",
        "# esTrigramFreq = collections.Counter(esTrigrams)\n",
        "# esTrigramFreq.most_common(10)\n",
        "\n",
        "esQuadgrams = ngrams(words, 4)\n",
        "esQuadgramFreq = collections.Counter(esQuadgrams)\n",
        "esQuadgramFreq.most_common(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('for', 'the', 'sake', 'of'), 28),\n",
              " (('Very', 'true,', 'he', 'said.'), 26),\n",
              " (('the', 'interest', 'of', 'the'), 25),\n",
              " (('What', 'do', 'you', 'mean'), 24),\n",
              " (('at', 'the', 'same', 'time'), 22),\n",
              " (('the', 'rest', 'of', 'the'), 21),\n",
              " (('Yes,', 'he', 'said,', 'that'), 21),\n",
              " (('in', 'the', 'case', 'of'), 20),\n",
              " (('as', 'well', 'as', 'of'), 18),\n",
              " (('the', 'idea', 'of', 'good'), 18)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    }
  ]
}